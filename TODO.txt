âœ… Phase 1: Improvement Plan Overview

ğŸ”§ Core Improvements
- [ ] Speed up LLM responses
- [ ] Limit or summarize long context chunks
- [ ] Add loading indicator / spinner in Streamlit
- [ ] Enable multi-turn conversation (chat history)
- [ ] Switch to newer LangChain modules (langchain_ollama, langchain_chroma, etc.)

âœ¨ New Features to Add
- [ ] ğŸ” Document Search Mode: Show top-matching chunks as plain text before answering.
- [ ] ğŸ§  Memory Support: Enable multi-turn conversation using ConversationBufferMemory.
- [ ] ğŸ§¼ Chunk Preview UI: Let users see what content is matched before LLM answers.
- [ ] ğŸ—ƒï¸ PDF Upload via UI: Allow drag-drop PDF uploading through Streamlit.
- [ ] ğŸ“Š Token and Speed Metrics: Show total tokens processed + response time.
- [ ] ğŸ” Switch Between LLMs (Ollama / OpenAI / Together.ai) from a dropdown menu.
- [ ] ğŸ–¼ï¸ Light/Dark theme toggle in Streamlit
- [ ] ğŸ“ Chat export to text/markdown file