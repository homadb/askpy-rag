✅ Phase 1: Improvement Plan Overview

🔧 Core Improvements
- [ ] Speed up LLM responses
- [ ] Limit or summarize long context chunks
- [ ] Add loading indicator / spinner in Streamlit
- [ ] Enable multi-turn conversation (chat history)
- [ ] Switch to newer LangChain modules (langchain_ollama, langchain_chroma, etc.)

✨ New Features to Add
- [ ] 🔎 Document Search Mode: Show top-matching chunks as plain text before answering.
- [ ] 🧠 Memory Support: Enable multi-turn conversation using ConversationBufferMemory.
- [ ] 🧼 Chunk Preview UI: Let users see what content is matched before LLM answers.
- [ ] 🗃️ PDF Upload via UI: Allow drag-drop PDF uploading through Streamlit.
- [ ] 📊 Token and Speed Metrics: Show total tokens processed + response time.
- [ ] 🔐 Switch Between LLMs (Ollama / OpenAI / Together.ai) from a dropdown menu.
- [ ] 🖼️ Light/Dark theme toggle in Streamlit
- [ ] 📝 Chat export to text/markdown file